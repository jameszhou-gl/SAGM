[37m[36mINFO[0m[0m 03/12 21:43:10 | Command :: train_all.py VLCS0 --dataset VLCS --data_dir /home/guanglinzhou/scratch/domainbed/dataset --deterministic --trial_seed 0 --algorithm SAGM_DG --alpha 0.001 --lr 3e-5 --weight_decay 1e-4 --resnet_dropout 0.5 --swad False --steps 3000
Environment:
	Python: 3.11.5
	PyTorch: 2.0.1+cu117
	Torchvision: 0.15.2+cu117
	CUDA: 11.7
	CUDNN: 8500
	NumPy: 1.26.2
	PIL: 10.1.0
Args:
	algorithm: SAGM_DG
	checkpoint_freq: None
	configs: []
	data_dir: /home/guanglinzhou/scratch/domainbed/dataset
	dataset: VLCS
	debug: False
	deterministic: True
	evalmode: fast
	holdout_fraction: 0.2
	model_save: None
	name: VLCS0
	out_dir: train_output/VLCS/240312_21-43-10_VLCS0
	out_root: train_output/VLCS
	prebuild_loader: False
	seed: 0
	show: False
	steps: 3000
	tb_freq: 10
	test_envs: None
	trial_seed: 0
	unique_name: 240312_21-43-10_VLCS0
	work_dir: .
HParams:
	data_augmentation: True
	val_augment: False
	resnet18: False
	[36mresnet_dropout: 0.5
	[0mclass_balanced: False
	optimizer: adam
	freeze_bn: True
	pretrained: True
	[36mlr: 3e-05
	[0mbatch_size: 32
	[36mweight_decay: 0.0001
	[0mrho: 0.05
	[36malpha: 0.001
	[0m[36mswad: False
	[0mswad_kwargs: 
	  n_converge: 3
	  n_tolerance: 6
	  tolerance_ratio: 0.3
	test_batchsize: 128
	indomain_test: False
Dataset:
	[VLCS] #envs=4, #classes=5
	env0: Caltech101 (#1415)
	env1: LabelMe (#2656)
	env2: SUN09 (#3282)
	env3: VOC2007 (#3376)

[37m[36mINFO[0m[0m 03/12 21:43:12 | n_steps = 3000
[37m[36mINFO[0m[0m 03/12 21:43:12 | checkpoint_freq = 200
[37m[36mINFO[0m[0m 03/12 21:43:12 | n_steps is updated to 3000 => 3001 for checkpointing
[37m[36mINFO[0m[0m 03/12 21:43:12 | Target test envs = [[0], [1], [2], [3]]
[37m[36mINFO[0m[0m 03/12 21:43:12 | 
[37m[36mINFO[0m[0m 03/12 21:43:12 | Testenv name escaping te_Caltech101 -> te_Caltech101
[37m[36mINFO[0m[0m 03/12 21:43:12 | Test envs = [0], name = te_Caltech101
[37m[36mINFO[0m[0m 03/12 21:43:12 | Batch sizes for each domain: [0, 32, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/12 21:43:12 | steps-per-epoch for each domain: 66.41, 82.06, 84.41 -> min = 66.41
[37m[36mINFO[0m[0m 03/12 21:43:17 | # of params = 85802501
[37m[36mINFO[0m[0m 03/12 21:44:04 | test_in     test_out    train_in    train_out   tr_outloss  env0_in     env0_out    env1_out    env2_out    env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/12 21:44:04 | 0.422261    0.462898    0.000000    0.443205    1.404613    0.422261    0.462898    0.495292    0.429878    0.404444    0           0.000000    2.309558    4.839029    41.995026  
[37m[36mINFO[0m[0m 03/12 21:51:14 | 0.992049    0.996466    0.000000    0.849030    0.422510    0.992049    0.996466    0.813559    0.849085    0.884444    200         3.011765    0.560446    1.985016    33.343307  
[37m[36mINFO[0m[0m 03/12 21:58:29 | 0.969965    0.961131    0.000000    0.847790    0.411574    0.969965    0.961131    0.802260    0.855183    0.885926    400         6.023529    0.348131    2.005456    33.411360  
[37m[36mINFO[0m[0m 03/12 22:05:44 | 0.969965    0.985866    0.000000    0.848480    0.428330    0.969965    0.985866    0.806026    0.847561    0.891852    600         9.035294    0.275854    2.009370    32.939181  
[37m[36mINFO[0m[0m 03/12 22:12:58 | 0.970848    0.971731    0.000000    0.849014    0.475821    0.970848    0.971731    0.821092    0.842988    0.882963    800         12.047059   0.198253    2.006161    33.184186  
[37m[36mINFO[0m[0m 03/12 22:20:13 | 0.976148    0.978799    0.000000    0.846636    0.505357    0.976148    0.978799    0.822976    0.838415    0.878519    1000        15.058824   0.147310    2.002686    33.919062  
[37m[36mINFO[0m[0m 03/12 22:27:27 | 0.977032    0.985866    0.000000    0.837954    0.591364    0.977032    0.985866    0.790960    0.839939    0.882963    1200        18.070588   0.100221    2.004911    33.101846  
[37m[36mINFO[0m[0m 03/12 22:34:42 | 0.966431    0.978799    0.000000    0.834573    0.603476    0.966431    0.978799    0.800377    0.829268    0.874074    1400        21.082353   0.071465    2.008053    33.412280  
[37m[36mINFO[0m[0m 03/12 22:41:55 | 0.977032    0.982332    0.000000    0.843025    0.645409    0.977032    0.982332    0.800377    0.835366    0.893333    1600        24.094118   0.055456    2.002998    33.237577  
[37m[36mINFO[0m[0m 03/12 22:49:11 | 0.982332    0.985866    0.000000    0.844439    0.651009    0.982332    0.985866    0.796610    0.856707    0.880000    1800        27.105882   0.040554    2.007630    33.593861  
[37m[36mINFO[0m[0m 03/12 22:56:26 | 0.984099    0.985866    0.000000    0.840134    0.730892    0.984099    0.985866    0.800377    0.842988    0.877037    2000        30.117647   0.036039    2.006367    33.626121  
[37m[36mINFO[0m[0m 03/12 23:03:39 | 0.990283    0.982332    0.000000    0.824598    0.727248    0.990283    0.982332    0.785311    0.827744    0.860741    2200        33.129412   0.030343    2.000282    33.527271  
[37m[36mINFO[0m[0m 03/12 23:10:54 | 0.986749    0.982332    0.000000    0.826998    0.741239    0.986749    0.982332    0.770245    0.829268    0.881481    2400        36.141176   0.026604    2.006890    33.081875  
[37m[36mINFO[0m[0m 03/12 23:18:09 | 0.985866    0.982332    0.000000    0.823256    0.802762    0.985866    0.982332    0.789077    0.814024    0.866667    2600        39.152941   0.025187    2.011083    33.457147  
[37m[36mINFO[0m[0m 03/12 23:25:22 | 0.978799    0.975265    0.000000    0.829727    0.776923    0.978799    0.975265    0.794727    0.829268    0.865185    2800        42.164706   0.023326    2.003271    32.390927  
[37m[36mINFO[0m[0m 03/12 23:32:37 | 0.977032    0.975265    0.000000    0.821297    0.822493    0.977032    0.975265    0.774011    0.824695    0.865185    3000        45.176471   0.021192    2.009864    33.080368  
[37m[36mINFO[0m[0m 03/12 23:32:37 | ---
[37m[36mINFO[0m[0m 03/12 23:32:37 | oracle = 99.205%
[37m[36mINFO[0m[0m 03/12 23:32:37 | iid = 99.205%
[37m[36mINFO[0m[0m 03/12 23:32:37 | last = 97.703%
[37m[36mINFO[0m[0m 03/12 23:32:37 | last (inD) = 82.130%
[37m[36mINFO[0m[0m 03/12 23:32:37 | iid (inD) = 84.903%
[37m[36mINFO[0m[0m 03/12 23:32:37 | 
[37m[36mINFO[0m[0m 03/12 23:32:38 | Testenv name escaping te_LabelMe -> te_LabelMe
[37m[36mINFO[0m[0m 03/12 23:32:38 | Test envs = [1], name = te_LabelMe
[37m[36mINFO[0m[0m 03/12 23:32:38 | Batch sizes for each domain: [32, 0, 32, 32] (total=96)
[37m[36mINFO[0m[0m 03/12 23:32:38 | steps-per-epoch for each domain: 35.38, 82.06, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 03/12 23:32:41 | # of params = 85802501
[37m[36mINFO[0m[0m 03/12 23:33:53 | test_in     test_out    train_in    train_out   tr_outloss  env0_out    env1_in     env1_out    env2_out    env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/12 23:33:53 | 0.479529    0.474576    0.000000    0.541209    1.307909    0.692580    0.479529    0.474576    0.445122    0.485926    0           0.000000    2.160978    1.954607    70.289256  
[37m[36mINFO[0m[0m 03/12 23:41:45 | 0.675765    0.679849    0.000000    0.914533    0.232875    1.000000    0.675765    0.679849    0.838415    0.905185    200         5.653710    0.308908    2.004521    71.676094  
[37m[36mINFO[0m[0m 03/12 23:49:31 | 0.667294    0.661017    0.000000    0.913109    0.236826    1.000000    0.667294    0.661017    0.844512    0.894815    400         11.307420   0.151998    1.979211    70.091920  
[37m[36mINFO[0m[0m 03/12 23:57:16 | 0.632471    0.636535    0.000000    0.916666    0.253975    1.000000    0.632471    0.636535    0.855183    0.894815    600         16.961131   0.106567    1.979816    68.984757  
[37m[36mINFO[0m[0m 03/13 00:05:02 | 0.628235    0.625235    0.000000    0.917625    0.278509    1.000000    0.628235    0.625235    0.852134    0.900741    800         22.614841   0.067624    1.981687    68.835746  
[37m[36mINFO[0m[0m 03/13 00:12:49 | 0.612706    0.617702    0.000000    0.914182    0.314510    1.000000    0.612706    0.617702    0.853659    0.888889    1000        28.268551   0.045684    1.989930    69.595812  
[37m[36mINFO[0m[0m 03/13 00:20:37 | 0.656000    0.662900    0.000000    0.909509    0.347786    1.000000    0.656000    0.662900    0.829268    0.899259    1200        33.922261   0.031418    1.983558    70.720079  
[37m[36mINFO[0m[0m 03/13 00:28:22 | 0.641412    0.644068    0.000000    0.912587    0.294899    1.000000    0.641412    0.644068    0.841463    0.896296    1400        39.575972   0.027473    1.980657    69.518998  
[37m[36mINFO[0m[0m 03/13 00:36:07 | 0.634353    0.640301    0.000000    0.914590    0.335095    1.000000    0.634353    0.640301    0.844512    0.899259    1600        45.229682   0.017724    1.976457    69.505511  
[37m[36mINFO[0m[0m 03/13 00:43:54 | 0.629176    0.623352    0.000000    0.919092    0.346260    1.000000    0.629176    0.623352    0.850610    0.906667    1800        50.883392   0.015677    1.981205    70.460077  
[37m[36mINFO[0m[0m 03/13 00:51:41 | 0.620235    0.629002    0.000000    0.918613    0.349806    1.000000    0.620235    0.629002    0.852134    0.903704    2000        56.537102   0.016451    1.980621    70.806926  
[37m[36mINFO[0m[0m 03/13 00:59:29 | 0.609412    0.613936    0.000000    0.911570    0.349098    1.000000    0.609412    0.613936    0.838415    0.896296    2200        62.190813   0.015553    1.980634    71.760249  
[37m[36mINFO[0m[0m 03/13 01:07:14 | 0.622588    0.632768    0.000000    0.913617    0.334670    1.000000    0.622588    0.632768    0.846037    0.894815    2400        67.844523   0.014954    1.982286    69.095832  
[37m[36mINFO[0m[0m 03/13 01:15:03 | 0.616471    0.619586    0.000000    0.910175    0.359649    1.000000    0.616471    0.619586    0.847561    0.882963    2600        73.498233   0.011612    1.984598    71.858196  
[37m[36mINFO[0m[0m 03/13 01:22:24 | 0.645176    0.664783    0.000000    0.915650    0.371102    1.000000    0.645176    0.664783    0.852134    0.894815    2800        79.151943   0.010964    1.859159    69.154584  
[37m[36mINFO[0m[0m 03/13 01:29:44 | 0.624471    0.632768    0.000000    0.910160    0.377098    1.000000    0.624471    0.632768    0.846037    0.884444    3000        84.805654   0.011406    1.832279    73.655034  
[37m[36mINFO[0m[0m 03/13 01:29:44 | ---
[37m[36mINFO[0m[0m 03/13 01:29:44 | oracle = 67.576%
[37m[36mINFO[0m[0m 03/13 01:29:44 | iid = 62.918%
[37m[36mINFO[0m[0m 03/13 01:29:44 | last = 62.447%
[37m[36mINFO[0m[0m 03/13 01:29:44 | last (inD) = 91.016%
[37m[36mINFO[0m[0m 03/13 01:29:44 | iid (inD) = 91.909%
[37m[36mINFO[0m[0m 03/13 01:29:44 | 
[37m[36mINFO[0m[0m 03/13 01:29:44 | Testenv name escaping te_SUN09 -> te_SUN09
[37m[36mINFO[0m[0m 03/13 01:29:44 | Test envs = [2], name = te_SUN09
[37m[36mINFO[0m[0m 03/13 01:29:44 | Batch sizes for each domain: [32, 32, 0, 32] (total=96)
[37m[36mINFO[0m[0m 03/13 01:29:44 | steps-per-epoch for each domain: 35.38, 66.41, 84.41 -> min = 35.38
[37m[36mINFO[0m[0m 03/13 01:29:47 | # of params = 85802501
[37m[36mINFO[0m[0m 03/13 01:30:29 | test_in     test_out    train_in    train_out   tr_outloss  env0_out    env1_out    env2_in     env2_out    env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/13 01:30:29 | 0.364813    0.378049    0.000000    0.564103    1.092550    0.664311    0.568738    0.364813    0.378049    0.459259    0           0.000000    2.069039    1.950363    39.468509  
[37m[36mINFO[0m[0m 03/13 01:37:15 | 0.771135    0.766768    0.000000    0.898439    0.265122    1.000000    0.807910    0.771135    0.766768    0.887407    200         5.653710    0.378411    1.833351    39.398740  
[37m[36mINFO[0m[0m 03/13 01:44:00 | 0.753237    0.731707    0.000000    0.900548    0.294641    1.000000    0.809793    0.753237    0.731707    0.891852    400         11.307420   0.231007    1.833860    38.889712  
[37m[36mINFO[0m[0m 03/13 01:50:47 | 0.761234    0.757622    0.000000    0.901578    0.282418    1.000000    0.817326    0.761234    0.757622    0.887407    600         16.961131   0.171534    1.835207    39.325352  
[37m[36mINFO[0m[0m 03/13 01:57:32 | 0.750952    0.743902    0.000000    0.894221    0.308391    1.000000    0.804143    0.750952    0.743902    0.878519    800         22.614841   0.130319    1.832946    38.978902  
[37m[36mINFO[0m[0m 03/13 02:04:19 | 0.784463    0.756098    0.000000    0.891216    0.363829    1.000000    0.796610    0.784463    0.756098    0.877037    1000        28.268551   0.085277    1.833516    39.898271  
[37m[36mINFO[0m[0m 03/13 02:11:05 | 0.763899    0.736280    0.000000    0.892471    0.379578    1.000000    0.800377    0.763899    0.736280    0.877037    1200        33.922261   0.062400    1.833938    39.645313  
[37m[36mINFO[0m[0m 03/13 02:17:51 | 0.759330    0.711890    0.000000    0.893141    0.415993    1.000000    0.809793    0.759330    0.711890    0.869630    1400        39.575972   0.041939    1.832144    39.530438  
[37m[36mINFO[0m[0m 03/13 02:24:38 | 0.772658    0.740854    0.000000    0.886503    0.450319    1.000000    0.792844    0.772658    0.740854    0.866667    1600        45.229682   0.032267    1.835511    39.115309  
[37m[36mINFO[0m[0m 03/13 02:31:24 | 0.752475    0.719512    0.000000    0.885382    0.482839    1.000000    0.790960    0.752475    0.719512    0.865185    1800        50.883392   0.025147    1.835494    39.724197  
[37m[36mINFO[0m[0m 03/13 02:38:10 | 0.765042    0.745427    0.000000    0.884260    0.501399    1.000000    0.789077    0.765042    0.745427    0.863704    2000        56.537102   0.021688    1.833586    38.643372  
[37m[36mINFO[0m[0m 03/13 02:44:57 | 0.757426    0.736280    0.000000    0.883365    0.481172    1.000000    0.783427    0.757426    0.736280    0.866667    2200        62.190813   0.018543    1.837430    39.414196  
[37m[36mINFO[0m[0m 03/13 02:51:43 | 0.768469    0.737805    0.000000    0.887357    0.521169    1.000000    0.790960    0.768469    0.737805    0.871111    2400        67.844523   0.016950    1.835307    39.002722  
[37m[36mINFO[0m[0m 03/13 02:58:29 | 0.753998    0.736280    0.000000    0.884218    0.495856    1.000000    0.781544    0.753998    0.736280    0.871111    2600        73.498233   0.016845    1.834036    39.077800  
[37m[36mINFO[0m[0m 03/13 03:05:15 | 0.716679    0.702744    0.000000    0.878251    0.533103    1.000000    0.774011    0.716679    0.702744    0.860741    2800        79.151943   0.012025    1.833892    39.203012  
[37m[36mINFO[0m[0m 03/13 03:12:00 | 0.770754    0.756098    0.000000    0.890814    0.484229    1.000000    0.790960    0.770754    0.756098    0.881481    3000        84.805654   0.011893    1.832650    39.047222  
[37m[36mINFO[0m[0m 03/13 03:12:00 | ---
[37m[36mINFO[0m[0m 03/13 03:12:00 | oracle = 77.113%
[37m[36mINFO[0m[0m 03/13 03:12:00 | iid = 76.123%
[37m[36mINFO[0m[0m 03/13 03:12:00 | last = 77.075%
[37m[36mINFO[0m[0m 03/13 03:12:00 | last (inD) = 89.081%
[37m[36mINFO[0m[0m 03/13 03:12:00 | iid (inD) = 90.158%
[37m[36mINFO[0m[0m 03/13 03:12:00 | 
[37m[36mINFO[0m[0m 03/13 03:12:00 | Testenv name escaping te_VOC2007 -> te_VOC2007
[37m[36mINFO[0m[0m 03/13 03:12:00 | Test envs = [3], name = te_VOC2007
[37m[36mINFO[0m[0m 03/13 03:12:00 | Batch sizes for each domain: [32, 32, 32, 0] (total=96)
[37m[36mINFO[0m[0m 03/13 03:12:01 | steps-per-epoch for each domain: 35.38, 66.41, 82.06 -> min = 35.38
[37m[36mINFO[0m[0m 03/13 03:12:03 | # of params = 85802501
[37m[36mINFO[0m[0m 03/13 03:12:43 | test_in     test_out    train_in    train_out   tr_outloss  env0_out    env1_out    env2_out    env3_in     env3_out    step        epoch       loss        step_time   eval_time  
[37m[36mINFO[0m[0m 03/13 03:12:43 | 0.433913    0.414815    0.000000    0.539429    1.190336    0.674912    0.534840    0.408537    0.433913    0.414815    0           0.000000    2.121028    1.768432    37.916358  
[37m[36mINFO[0m[0m 03/13 03:19:27 | 0.814143    0.825185    0.000000    0.869315    0.330651    1.000000    0.798493    0.809451    0.814143    0.825185    200         5.653710    0.417301    1.829598    38.478613  
[37m[36mINFO[0m[0m 03/13 03:26:13 | 0.830433    0.817778    0.000000    0.888296    0.304065    1.000000    0.817326    0.847561    0.830433    0.817778    400         11.307420   0.272246    1.834463    38.312356  
[37m[36mINFO[0m[0m 03/13 03:32:58 | 0.803406    0.800000    0.000000    0.879417    0.317214    1.000000    0.781544    0.856707    0.803406    0.800000    600         16.961131   0.188354    1.834562    38.043292  
[37m[36mINFO[0m[0m 03/13 03:39:43 | 0.820807    0.802963    0.000000    0.878551    0.392028    1.000000    0.807910    0.827744    0.820807    0.802963    800         22.614841   0.144192    1.832804    38.547136  
[37m[36mINFO[0m[0m 03/13 03:46:27 | 0.808219    0.788148    0.000000    0.887070    0.402136    1.000000    0.806026    0.855183    0.808219    0.788148    1000        28.268551   0.099912    1.831331    38.527011  
[37m[36mINFO[0m[0m 03/13 03:53:13 | 0.804147    0.795556    0.000000    0.884111    0.466979    1.000000    0.815443    0.836890    0.804147    0.795556    1200        33.922261   0.068474    1.830773    38.931379  
[37m[36mINFO[0m[0m 03/13 03:59:57 | 0.793780    0.779259    0.000000    0.876309    0.448372    1.000000    0.796610    0.832317    0.793780    0.779259    1400        39.575972   0.050154    1.829673    38.534804  
[37m[36mINFO[0m[0m 03/13 04:06:42 | 0.783043    0.780741    0.000000    0.878850    0.475315    1.000000    0.796610    0.839939    0.783043    0.780741    1600        45.229682   0.038380    1.831116    38.882645  
[37m[36mINFO[0m[0m 03/13 04:13:28 | 0.783043    0.780741    0.000000    0.880943    0.549674    1.000000    0.813559    0.829268    0.783043    0.780741    1800        50.883392   0.029150    1.833662    38.706691  
[37m[36mINFO[0m[0m 03/13 04:20:12 | 0.790448    0.774815    0.000000    0.879358    0.527614    1.000000    0.796610    0.841463    0.790448    0.774815    2000        56.537102   0.021631    1.829990    38.781171  
[37m[36mINFO[0m[0m 03/13 04:26:58 | 0.754165    0.764444    0.000000    0.879717    0.524896    1.000000    0.802260    0.836890    0.754165    0.764444    2200        62.190813   0.020123    1.832769    38.546566  
[37m[36mINFO[0m[0m 03/13 04:33:47 | 0.777860    0.761481    0.000000    0.878192    0.520382    1.000000    0.802260    0.832317    0.777860    0.761481    2400        67.844523   0.017285    1.831525    43.514985  
[37m[36mINFO[0m[0m 03/13 04:40:34 | 0.785635    0.767407    0.000000    0.872543    0.587785    1.000000    0.785311    0.832317    0.785635    0.767407    2600        73.498233   0.013414    1.820559    42.901788  
[37m[36mINFO[0m[0m 03/13 04:47:20 | 0.776379    0.779259    0.000000    0.873918    0.517970    1.000000    0.790960    0.830793    0.776379    0.779259    2800        79.151943   0.016075    1.822066    41.630568  
[37m[36mINFO[0m[0m 03/13 04:54:06 | 0.762680    0.751111    0.000000    0.868537    0.539941    1.000000    0.770245    0.835366    0.762680    0.751111    3000        84.805654   0.014523    1.819847    41.128384  
[37m[36mINFO[0m[0m 03/13 04:54:06 | ---
[37m[36mINFO[0m[0m 03/13 04:54:06 | oracle = 81.414%
[37m[36mINFO[0m[0m 03/13 04:54:06 | iid = 83.043%
[37m[36mINFO[0m[0m 03/13 04:54:06 | last = 76.268%
[37m[36mINFO[0m[0m 03/13 04:54:06 | last (inD) = 86.854%
[37m[36mINFO[0m[0m 03/13 04:54:06 | iid (inD) = 88.830%
[37m[36mINFO[0m[0m 03/13 04:54:06 | === Summary ===
[37m[36mINFO[0m[0m 03/13 04:54:06 | Command: train_all.py VLCS0 --dataset VLCS --data_dir /home/guanglinzhou/scratch/domainbed/dataset --deterministic --trial_seed 0 --algorithm SAGM_DG --alpha 0.001 --lr 3e-5 --weight_decay 1e-4 --resnet_dropout 0.5 --swad False --steps 3000
[37m[36mINFO[0m[0m 03/13 04:54:06 | Unique name: 240312_21-43-10_VLCS0
[37m[36mINFO[0m[0m 03/13 04:54:06 | Out path: train_output/VLCS/240312_21-43-10_VLCS0
[37m[36mINFO[0m[0m 03/13 04:54:06 | Algorithm: SAGM_DG
[37m[36mINFO[0m[0m 03/13 04:54:06 | Dataset: VLCS
+------------+------------+---------+---------+---------+---------+
| Selection  | Caltech101 | LabelMe |  SUN09  | VOC2007 |   Avg.  |
+------------+------------+---------+---------+---------+---------+
|   oracle   |  99.205%   | 67.576% | 77.113% | 81.414% | 81.327% |
|    iid     |  99.205%   | 62.918% | 76.123% | 83.043% | 80.322% |
|    last    |  97.703%   | 62.447% | 77.075% | 76.268% | 78.373% |
| last (inD) |  82.130%   | 91.016% | 89.081% | 86.854% | 87.270% |
| iid (inD)  |  84.903%   | 91.909% | 90.158% | 88.830% | 88.950% |
+------------+------------+---------+---------+---------+---------+
